{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "348b4fcd",
   "metadata": {},
   "source": [
    "Remove before Submitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f28da059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable autoreload in Jupyter\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1382d6c0",
   "metadata": {},
   "source": [
    "# Imports and Seed Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71755b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All random seeds set to 51 for reproducibility\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set environment variables for reproducibility BEFORE importing torch\n",
    "os.environ['PYTHONHASHSEED'] = '51'\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to sys.path for module imports\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "import wandb\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import fiftyone as fo\n",
    "from torch.optim import Adam\n",
    "from pathlib import Path\n",
    "from tabulate import tabulate\n",
    "\n",
    "from src.datasets import CustomTorchImageDataset\n",
    "from src.models import (\n",
    "    Net,\n",
    "    LateFusionModel,\n",
    "    ConcatIntermediateNet,\n",
    "    AdditionIntermediateNet,\n",
    "    HadamardIntermediateNet,\n",
    ")\n",
    "from src.training import train_model\n",
    "from src.utils import (\n",
    "    set_seeds,\n",
    "    create_deterministic_training_dataloader,\n",
    "    get_rgb_input,\n",
    "    get_lidar_input,\n",
    "    get_mm_intermediate_inputs,\n",
    "    get_mm_late_inputs,\n",
    ")\n",
    "\n",
    "set_seeds(51)\n",
    "\n",
    "PROJECT_NAME = \"cilp-extended-assessment\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec04071a",
   "metadata": {},
   "source": [
    "# Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec17429d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing samples...\n",
      " 100% |███████████████| 3228/3228 [88.9ms elapsed, 0s remaining, 36.3K samples/s]   \n",
      "Total samples in dataset: 1076\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 64\n",
    "\n",
    "dataset_name = \"cilp_assessment\"\n",
    "\n",
    "# Load the FiftyOne dataset from disk\n",
    "dataset = fo.Dataset.from_dir(\n",
    "    dataset_dir=Path.cwd().parent / dataset_name,\n",
    "    dataset_type=fo.types.FiftyOneDataset,\n",
    ")\n",
    "\n",
    "print(f\"Total samples in dataset: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf0dad5",
   "metadata": {},
   "source": [
    "Extract train and test split of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12eeaf0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 897\n",
      "Validation samples: 179\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset.match_tags(\"train\")\n",
    "val_dataset = dataset.match_tags(\"validation\")\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9e903f",
   "metadata": {},
   "source": [
    "Generate custom torch datasets to use dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3172e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cpu\n",
      "CustomTorchImageDataset initialized with 897 samples.\n",
      "CustomTorchImageDataset initialized with 179 samples.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Device: \", device)\n",
    "\n",
    "torch_train_dataset = CustomTorchImageDataset(\n",
    "    fiftyone_dataset=train_dataset,\n",
    "    img_size=IMG_SIZE,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "torch_val_dataset = CustomTorchImageDataset(\n",
    "    fiftyone_dataset=val_dataset,\n",
    "    img_size=IMG_SIZE,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407ea3b1",
   "metadata": {},
   "source": [
    "Create a DataLoader and use a deterministic setup for training to make the results reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3007f6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = create_deterministic_training_dataloader(\n",
    "    torch_train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    torch_val_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18de0803",
   "metadata": {},
   "source": [
    "For the loss function, we use the same one as in the assessment: **BCEWithLogitsLoss**. This loss works well with a single output neuron for binary classification. In later tasks, we set *num_classes=1* to ensure the model has only one output neuron, which aligns with this loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78aea855",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39828969",
   "metadata": {},
   "source": [
    "We initialize our table for the comparison of the different architectures at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff1af0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = [\n",
    "    [\"Metrics\", \"Validation Loss\", \"Parameters (M)\", \"Training Time / epoch (s)\", \"GPU Memory (MB)\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28afee92",
   "metadata": {},
   "source": [
    "# Intermediate Fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765fb005",
   "metadata": {},
   "source": [
    "For training, we need to define the input format of a batch. For all intermediate architectures, we use the same format. It is defined within the utils.py."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec20e44",
   "metadata": {},
   "source": [
    "## Concatenation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f18c67",
   "metadata": {},
   "source": [
    "Our first intermediate architecture uses **Concatenation**. Here, we use separate convolutions for both modalities. Afterwards, we concatenate the results and pass them through a feedforward network before the final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "449a9cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkarl-schuetz\u001b[0m (\u001b[33mkarl-schuetz-hasso-plattner-institut\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/matti/Master/3. Semester/Hands-on Computer Vision/lab2/CILP-Assessment-Multimodal-Learning/notebooks/wandb/run-20251226_134342-duz41f0r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment/runs/duz41f0r' target=\"_blank\">ConcatIntermediateNet</a></strong> to <a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment' target=\"_blank\">https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment/runs/duz41f0r' target=\"_blank\">https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment/runs/duz41f0r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mm_concat_intermediate_net\n",
      "All random seeds set to 51 for reproducibility\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁█</td></tr><tr><td>learning_rate</td><td>▁▁</td></tr><tr><td>train_loss</td><td>█▁</td></tr><tr><td>valid_loss</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>2</td></tr><tr><td>learning_rate</td><td>0.0001</td></tr><tr><td>train_loss</td><td>0.23266</td></tr><tr><td>valid_loss</td><td>0.21223</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ConcatIntermediateNet</strong> at: <a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment/runs/duz41f0r' target=\"_blank\">https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment/runs/duz41f0r</a><br> View project at: <a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment' target=\"_blank\">https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251226_134342-duz41f0r/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 2\n",
    "\n",
    "gpu_mem_before = torch.cuda.memory_allocated()\n",
    "mm_concat_intermediate_net = ConcatIntermediateNet(rgb_ch=4, xyz_ch=4).to(device)\n",
    "# We collect this after model creation to measure model memory usage\n",
    "gpu_mem_after = torch.cuda.memory_allocated()\n",
    "\n",
    "mm_concat_intermediate_opt = Adam(mm_concat_intermediate_net.parameters(), lr=0.0001)\n",
    "mm_concat_intermediate_save_path = Path.cwd().parent / \"checkpoints\" / \"02_mm_concat_intermediate_net.pth\"\n",
    "mm_concat_intermediate_run = wandb.init(project=PROJECT_NAME, name=f\"{ConcatIntermediateNet.__name__}\")\n",
    "\n",
    "print(\"Training mm_concat_intermediate_net\")\n",
    "set_seeds(51)\n",
    "mm_concat_intermediate_train_loss, mm_concat_intermediate_valid_loss, mm_concat_intermediate_train_time = train_model(\n",
    "    mm_concat_intermediate_net,\n",
    "    mm_concat_intermediate_opt,\n",
    "    loss_func,\n",
    "    get_mm_intermediate_inputs,\n",
    "    epochs,\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    save_path=mm_concat_intermediate_save_path,\n",
    "    run=mm_concat_intermediate_run,\n",
    ")\n",
    "mm_concat_intermediate_num_params = mm_concat_intermediate_net.get_number_of_parameters() / 1e6  # in millions\n",
    "\n",
    "table.append([\n",
    "    \"Intermediate Fusion (Concatenation)\",\n",
    "    np.min(mm_concat_intermediate_valid_loss),\n",
    "    mm_concat_intermediate_num_params,\n",
    "    mm_concat_intermediate_train_time / epochs,\n",
    "    (gpu_mem_after - gpu_mem_before) / (1024 ** 2),\n",
    "])\n",
    "\n",
    "mm_concat_intermediate_run.finish()\n",
    "\n",
    "del mm_concat_intermediate_net, mm_concat_intermediate_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286e9989",
   "metadata": {},
   "source": [
    "## Addition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac53ab61",
   "metadata": {},
   "source": [
    "Now we use **Addition** as our intermediate architecture. Here, we apply separate convolutions to both modalities. Afterwards, we perform element-wise addition of the partial results and pass the sum through a feedforward network before the final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e07eff51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/matti/Master/3. Semester/Hands-on Computer Vision/lab2/CILP-Assessment-Multimodal-Learning/notebooks/wandb/run-20251226_134401-cr5ewyxh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment/runs/cr5ewyxh' target=\"_blank\">AdditionIntermediateNet</a></strong> to <a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment' target=\"_blank\">https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment/runs/cr5ewyxh' target=\"_blank\">https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment/runs/cr5ewyxh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mm_addition_intermediate_net\n",
      "All random seeds set to 51 for reproducibility\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁█</td></tr><tr><td>learning_rate</td><td>▁▁</td></tr><tr><td>train_loss</td><td>█▁</td></tr><tr><td>valid_loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>2</td></tr><tr><td>learning_rate</td><td>0.0001</td></tr><tr><td>train_loss</td><td>0.23474</td></tr><tr><td>valid_loss</td><td>0.20454</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">AdditionIntermediateNet</strong> at: <a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment/runs/cr5ewyxh' target=\"_blank\">https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment/runs/cr5ewyxh</a><br> View project at: <a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment' target=\"_blank\">https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251226_134401-cr5ewyxh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 2\n",
    "\n",
    "gpu_mem_before = torch.cuda.memory_allocated()\n",
    "mm_addition_intermediate_net = AdditionIntermediateNet(rgb_ch=4, xyz_ch=4).to(device)\n",
    "gpu_mem_after = torch.cuda.memory_allocated()\n",
    "\n",
    "mm_addition_intermediate_opt = Adam(mm_addition_intermediate_net.parameters(), lr=0.0001)\n",
    "mm_addition_intermediate_save_path = Path.cwd().parent / \"checkpoints\" / \"02_mm_addition_intermediate_net.pth\"\n",
    "mm_addition_intermediate_run = wandb.init(project=PROJECT_NAME, name=f\"{AdditionIntermediateNet.__name__}\")\n",
    "\n",
    "print(\"Training mm_addition_intermediate_net\")\n",
    "set_seeds(51)\n",
    "mm_addition_intermediate_train_loss, mm_addition_intermediate_valid_loss, mm_addition_intermediate_train_time = train_model(\n",
    "    mm_addition_intermediate_net,\n",
    "    mm_addition_intermediate_opt,\n",
    "    loss_func,\n",
    "    get_mm_intermediate_inputs,\n",
    "    epochs,\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    save_path=mm_addition_intermediate_save_path,\n",
    "    run=mm_addition_intermediate_run,\n",
    ")\n",
    "mm_addition_intermediate_num_params = mm_addition_intermediate_net.get_number_of_parameters() / 1e6  # in millions\n",
    "\n",
    "table.append([\n",
    "    \"Intermediate Fusion (Addition)\",\n",
    "    np.min(mm_addition_intermediate_valid_loss),\n",
    "    mm_addition_intermediate_num_params,\n",
    "    mm_addition_intermediate_train_time / epochs,\n",
    "    (gpu_mem_after - gpu_mem_before) / (1024 ** 2),\n",
    "])\n",
    "\n",
    "mm_addition_intermediate_run.finish()\n",
    "\n",
    "del mm_addition_intermediate_net, mm_addition_intermediate_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082126b5",
   "metadata": {},
   "source": [
    "## Hadamard Product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41531864",
   "metadata": {},
   "source": [
    "As the final intermediate strategy, we use the **Hadamard Product**. Here, we apply separate convolutions to both modalities. Afterwards, we perform element-wise multiplication of the partial results and pass the product through a feedforward network before the final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2023219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/matti/Master/3. Semester/Hands-on Computer Vision/lab2/CILP-Assessment-Multimodal-Learning/notebooks/wandb/run-20251226_134414-9dvtwjau</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment/runs/9dvtwjau' target=\"_blank\">HadamardIntermediateNet</a></strong> to <a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment' target=\"_blank\">https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment/runs/9dvtwjau' target=\"_blank\">https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment/runs/9dvtwjau</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mm_hadamard_intermediate_net\n",
      "All random seeds set to 51 for reproducibility\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁█</td></tr><tr><td>learning_rate</td><td>▁▁</td></tr><tr><td>train_loss</td><td>█▁</td></tr><tr><td>valid_loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>2</td></tr><tr><td>learning_rate</td><td>0.0001</td></tr><tr><td>train_loss</td><td>0.23152</td></tr><tr><td>valid_loss</td><td>0.20386</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">HadamardIntermediateNet</strong> at: <a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment/runs/9dvtwjau' target=\"_blank\">https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment/runs/9dvtwjau</a><br> View project at: <a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment' target=\"_blank\">https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251226_134414-9dvtwjau/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 2\n",
    "\n",
    "gpu_mem_before = torch.cuda.memory_allocated()\n",
    "mm_hadamard_intermediate_net = HadamardIntermediateNet(rgb_ch=4, xyz_ch=4).to(device)\n",
    "gpu_mem_after = torch.cuda.memory_allocated()\n",
    "\n",
    "mm_hadamard_intermediate_opt = Adam(mm_hadamard_intermediate_net.parameters(), lr=0.0001)\n",
    "mm_hadamard_intermediate_save_path = Path.cwd().parent / \"checkpoints\" / \"02_mm_hadamard_intermediate_net.pth\"\n",
    "mm_hadamard_intermediate_run = wandb.init(project=PROJECT_NAME, name=f\"{HadamardIntermediateNet.__name__}\")\n",
    "\n",
    "print(\"Training mm_hadamard_intermediate_net\")\n",
    "set_seeds(51)\n",
    "mm_hadamard_intermediate_train_loss, mm_hadamard_intermediate_valid_loss, mm_hadamard_intermediate_train_time = train_model(\n",
    "    mm_hadamard_intermediate_net,\n",
    "    mm_hadamard_intermediate_opt,\n",
    "    loss_func,\n",
    "    get_mm_intermediate_inputs,\n",
    "    epochs,\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    save_path=mm_hadamard_intermediate_save_path,\n",
    "    run=mm_hadamard_intermediate_run,\n",
    ")\n",
    "mm_hadamard_intermediate_num_params = mm_hadamard_intermediate_net.get_number_of_parameters() / 1e6  # in millions\n",
    "\n",
    "table.append([\n",
    "    \"Intermediate Fusion (Hadamard)\",\n",
    "    np.min(mm_hadamard_intermediate_valid_loss),\n",
    "    mm_hadamard_intermediate_num_params,\n",
    "    mm_hadamard_intermediate_train_time / epochs,\n",
    "    (gpu_mem_after - gpu_mem_before) / (1024 ** 2),\n",
    "])\n",
    "\n",
    "mm_hadamard_intermediate_run.finish()\n",
    "\n",
    "del mm_hadamard_intermediate_net, mm_hadamard_intermediate_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bae4c69",
   "metadata": {},
   "source": [
    "## Advantages and Limitations\n",
    "\n",
    "Intermediate fusion models enable the processing of multiple modalities before combining them. This allows the network to extract important features through convolutions from each modality before making the final prediction. We explored several fusion strategies:\n",
    "\n",
    "Concatenation increases the input size of the feedforward layer, resulting in a large number of parameters. Consequently, the model is bigger and requires more computation and time. However, concatenation still gives the model the opportunity to ignore less relevant modalities and focus on the most important information.\n",
    "\n",
    "Addition and Hadamard Product fusion combine the modalities mathematically at an earlier stage. This reduces the number of parameters since the output size after summing or multiplying remains the same. But it can obscure differences between modalities. For example, two samples with very different Lidar and RGB features could produce the same element-wise sum or product, potentially making it harder for the model to distinguish between them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e08237",
   "metadata": {},
   "source": [
    "# Late Fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1008b1d1",
   "metadata": {},
   "source": [
    "Now we use Late Fusion. Here, we first process each modality independently through separate convolutional and feedforward layers. Afterwards, we combine the outputs of both modalities using concatenation, and then produce the final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3a8637",
   "metadata": {},
   "source": [
    "## RGB Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1de25f9",
   "metadata": {},
   "source": [
    "First, we need to train the RGB classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d795c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/matti/Master/3. Semester/Hands-on Computer Vision/lab2/CILP-Assessment-Multimodal-Learning/notebooks/wandb/run-20251226_134437-s8ogh2ru</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment/runs/s8ogh2ru' target=\"_blank\">RGB_Net_Training</a></strong> to <a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment' target=\"_blank\">https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment/runs/s8ogh2ru' target=\"_blank\">https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment/runs/s8ogh2ru</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training rgb_net\n",
      "All random seeds set to 51 for reproducibility\n"
     ]
    }
   ],
   "source": [
    "epochs_rgb = 2\n",
    "\n",
    "gpu_mem_before = torch.cuda.memory_allocated()\n",
    "rgb_net = Net(in_ch=4).to(device)\n",
    "gpu_mem_after = torch.cuda.memory_allocated()\n",
    "gpu_mem_rgb = gpu_mem_after - gpu_mem_before\n",
    "\n",
    "rgb_opt = Adam(rgb_net.parameters(), lr=0.0001)\n",
    "rgb_save_path = Path.cwd().parent / \"checkpoints\" / \"02_rgb_net.pth\"\n",
    "rgb_run = wandb.init(project=PROJECT_NAME, name=\"RGB_Net_Training\")\n",
    "\n",
    "print(\"Training rgb_net\")\n",
    "set_seeds(51)\n",
    "rgb_train_loss, rgb_valid_loss, rgb_train_time = train_model(\n",
    "    rgb_net,\n",
    "    rgb_opt,\n",
    "    loss_func,\n",
    "    get_rgb_input,\n",
    "    epochs_rgb,\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    save_path=rgb_save_path,\n",
    "    run=rgb_run,\n",
    ")\n",
    "\n",
    "rgb_run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082814bf",
   "metadata": {},
   "source": [
    "## Lidar Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bd0a28",
   "metadata": {},
   "source": [
    "We also need a Lidar classifier before using the late fusion model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5e49e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁█</td></tr><tr><td>learning_rate</td><td>▁▁</td></tr><tr><td>train_loss</td><td>█▁</td></tr><tr><td>valid_loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>2</td></tr><tr><td>learning_rate</td><td>0.0001</td></tr><tr><td>train_loss</td><td>0.23007</td></tr><tr><td>valid_loss</td><td>0.20601</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">RGB_Net_Training</strong> at: <a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment/runs/s8ogh2ru' target=\"_blank\">https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment/runs/s8ogh2ru</a><br> View project at: <a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment' target=\"_blank\">https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251226_134437-s8ogh2ru/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/matti/Master/3. Semester/Hands-on Computer Vision/lab2/CILP-Assessment-Multimodal-Learning/notebooks/wandb/run-20251226_134452-b7ex58hi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment/runs/b7ex58hi' target=\"_blank\">Lidar_Net_Training</a></strong> to <a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment' target=\"_blank\">https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment/runs/b7ex58hi' target=\"_blank\">https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment/runs/b7ex58hi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training lidar_net\n",
      "All random seeds set to 51 for reproducibility\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs_xyz = 2\n",
    "\n",
    "gpu_mem_before = torch.cuda.memory_allocated()\n",
    "xyz_net = Net(in_ch=4).to(device)\n",
    "gpu_mem_after = torch.cuda.memory_allocated()\n",
    "gpu_mem_xyz = gpu_mem_after - gpu_mem_before\n",
    "\n",
    "xyz_opt = Adam(xyz_net.parameters(), lr=0.0001)\n",
    "xyz_save_path = Path.cwd().parent / \"checkpoints\" / \"02_xyz_net.pth\"\n",
    "xyz_run = wandb.init(project=PROJECT_NAME, name=\"Lidar_Net_Training\")\n",
    "\n",
    "print(\"Training lidar_net\")\n",
    "set_seeds(51)\n",
    "xyz_train_loss, xyz_valid_loss, xyz_train_time = train_model(\n",
    "    xyz_net,\n",
    "    xyz_opt,\n",
    "    loss_func,\n",
    "    get_lidar_input,\n",
    "    epochs_xyz,\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    save_path=xyz_save_path,\n",
    "    run=xyz_run,\n",
    ")\n",
    "\n",
    "xyz_run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced6b55a",
   "metadata": {},
   "source": [
    "## Late Fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15baaa05",
   "metadata": {},
   "source": [
    "Load best performing models from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81c93d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgb_net.load_state_dict(torch.load(rgb_save_path))\n",
    "xyz_net.load_state_dict(torch.load(xyz_save_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072ee642",
   "metadata": {},
   "source": [
    "Disable gradient updates for the *rgb_net* and *xyz_net* to train only the late fusion model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b733f4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "networks = [rgb_net, xyz_net]\n",
    "\n",
    "for network in networks:\n",
    "    for param in network.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18173566",
   "metadata": {},
   "source": [
    "We train the late fusion component without updating the weights of the fused models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "661387e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁█</td></tr><tr><td>learning_rate</td><td>▁▁</td></tr><tr><td>train_loss</td><td>█▁</td></tr><tr><td>valid_loss</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>2</td></tr><tr><td>learning_rate</td><td>0.0001</td></tr><tr><td>train_loss</td><td>0.24168</td></tr><tr><td>valid_loss</td><td>0.24108</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Lidar_Net_Training</strong> at: <a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment/runs/b7ex58hi' target=\"_blank\">https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment/runs/b7ex58hi</a><br> View project at: <a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment' target=\"_blank\">https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251226_134452-b7ex58hi/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/matti/Master/3. Semester/Hands-on Computer Vision/lab2/CILP-Assessment-Multimodal-Learning/notebooks/wandb/run-20251226_134513-pieotckz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment/runs/pieotckz' target=\"_blank\">LateFusionModel</a></strong> to <a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment' target=\"_blank\">https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment/runs/pieotckz' target=\"_blank\">https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment/runs/pieotckz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mm_late_net\n",
      "All random seeds set to 51 for reproducibility\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁█</td></tr><tr><td>learning_rate</td><td>▁▁</td></tr><tr><td>train_loss</td><td>█▁</td></tr><tr><td>valid_loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>2</td></tr><tr><td>learning_rate</td><td>0.0001</td></tr><tr><td>train_loss</td><td>0.44547</td></tr><tr><td>valid_loss</td><td>0.43635</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">LateFusionModel</strong> at: <a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment/runs/pieotckz' target=\"_blank\">https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment/runs/pieotckz</a><br> View project at: <a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment' target=\"_blank\">https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251226_134513-pieotckz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 2\n",
    "\n",
    "gpu_mem_before = torch.cuda.memory_allocated()\n",
    "mm_late_net = LateFusionModel(rgb_net, xyz_net).to(device)\n",
    "gpu_mem_after = torch.cuda.memory_allocated()\n",
    "\n",
    "mm_late_opt = Adam(mm_late_net.parameters(), lr=0.0001)\n",
    "mm_late_save_path = Path.cwd().parent / \"checkpoints\" / \"02_mm_late_net.pth\"\n",
    "mm_late_run = wandb.init(project=PROJECT_NAME, name=f\"{LateFusionModel.__name__}\")\n",
    "\n",
    "print(\"Training mm_late_net\")\n",
    "set_seeds(51)\n",
    "mm_late_train_loss, mm_late_valid_loss, mm_late_train_time = train_model(\n",
    "    mm_late_net,\n",
    "    mm_late_opt,\n",
    "    loss_func,\n",
    "    get_mm_late_inputs,\n",
    "    epochs,\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    save_path=mm_late_save_path,\n",
    "    run=mm_late_run,\n",
    ")\n",
    "mm_late_num_params = mm_late_net.get_number_of_parameters() / 1e6  # in millions\n",
    "\n",
    "# Include the training times and epochs of the individual networks\n",
    "mm_late_train_time += rgb_train_time + xyz_train_time\n",
    "epochs += epochs_rgb + epochs_xyz\n",
    "\n",
    "table.append([\n",
    "    \"Late Fusion\",\n",
    "    np.min(mm_late_valid_loss),\n",
    "    mm_late_num_params,\n",
    "    mm_late_train_time / epochs,\n",
    "    (gpu_mem_after - gpu_mem_before + gpu_mem_rgb + gpu_mem_xyz) / (1024 ** 2),\n",
    "])\n",
    "\n",
    "mm_late_run.finish()\n",
    "\n",
    "del mm_late_net, mm_late_opt, rgb_net, xyz_net, rgb_opt, xyz_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf6266d",
   "metadata": {},
   "source": [
    "## Advantages and Limitations\n",
    "\n",
    "Using Late Fusion allows us to combine already trained classifiers, as demonstrated in this notebook. Combining pretrained models without retraining the entire network is a practical advantage. While this can be beneficial, it can be challenging to merge the outputs of the classifiers because they may lack essential information about the original modalities. If the classifiers have already made predictions, it can be difficult for the fusion model to produce an accurate final output. In contrast, an intermediate fusion model can access both modalities directly and exploit cross-modal interactions for prediction.\n",
    "\n",
    "Because Late Fusion requires two fully trained models as well as additional linear layers for fusion, this architecture involves a large number of parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e019fcbf",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442d8657",
   "metadata": {},
   "source": [
    "Print the comparision table while keeping all intermediate architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d339a264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+---------------------------------------+----------------------------------+----------------------------------+---------------+\n",
      "| Metrics                   |   Intermediate Fusion (Concatenation) |   Intermediate Fusion (Addition) |   Intermediate Fusion (Hadamard) |   Late Fusion |\n",
      "+===========================+=======================================+==================================+==================================+===============+\n",
      "| Validation Loss           |                              0.207008 |                         0.204541 |                         0.203858 |      0.436355 |\n",
      "+---------------------------+---------------------------------------+----------------------------------+----------------------------------+---------------+\n",
      "| Parameters (M)            |                             13.0159   |                         6.61585  |                         6.61585  |     26.2567   |\n",
      "+---------------------------+---------------------------------------+----------------------------------+----------------------------------+---------------+\n",
      "| Training Time / epoch (s) |                              3.42208  |                         2.60001  |                         2.64656  |      3.60885  |\n",
      "+---------------------------+---------------------------------------+----------------------------------+----------------------------------+---------------+\n",
      "| GPU Memory (MB)           |                              0        |                         0        |                         0        |      0        |\n",
      "+---------------------------+---------------------------------------+----------------------------------+----------------------------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "rows = list(zip(*table)) # transpose for tabulate\n",
    "print(tabulate(rows[1:], headers=rows[0], tablefmt=\"grid\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49144f86",
   "metadata": {},
   "source": [
    "Include written analysis (200-400 words) addressing:\n",
    "\n",
    "Which architecture performed best and why\n",
    "Trade-offs between parameter count and performance\n",
    "Recommendations for when to use each approach\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
