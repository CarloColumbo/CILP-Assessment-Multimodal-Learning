{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "779a3c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable autoreload in Jupyter\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22a62ab",
   "metadata": {},
   "source": [
    "# Imports and Seed Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "238079d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All random seeds set to 51 for reproducibility\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set environment variables for reproducibility BEFORE importing torch\n",
    "os.environ['PYTHONHASHSEED'] = '51'\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to sys.path for module imports\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "import wandb\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import ConcatDataset, DataLoader\n",
    "import fiftyone as fo\n",
    "from torch.optim import Adam\n",
    "from pathlib import Path\n",
    "from tabulate import tabulate\n",
    "\n",
    "from src.datasets import CustomTorchImageDataset\n",
    "from src.models import ConcatIntermediateNet, ConcatIntermediateNetWithStride\n",
    "from src.training import train_model\n",
    "from src.utils import (\n",
    "    set_seeds,\n",
    "    create_deterministic_training_dataloader,\n",
    "    infer_model,\n",
    "    get_mm_intermediate_inputs,\n",
    ")\n",
    "\n",
    "set_seeds(51)\n",
    "\n",
    "PROJECT_NAME = \"cilp-extended-assessment\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f45b1a1",
   "metadata": {},
   "source": [
    "# Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c263619b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing samples...\n",
      " 100% |███████████████| 3228/3228 [93.1ms elapsed, 0s remaining, 34.7K samples/s]   \n",
      "Total samples in dataset: 1076\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 64\n",
    "\n",
    "dataset_name = \"cilp_assessment\"\n",
    "\n",
    "# Load the FiftyOne dataset from disk\n",
    "dataset = fo.Dataset.from_dir(\n",
    "    dataset_dir=Path.cwd().parent / dataset_name,\n",
    "    dataset_type=fo.types.FiftyOneDataset,\n",
    ")\n",
    "\n",
    "print(f\"Total samples in dataset: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14cf6e4",
   "metadata": {},
   "source": [
    "Extract train and test split of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfaec291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 897\n",
      "Validation samples: 179\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset.match_tags(\"train\")\n",
    "val_dataset = dataset.match_tags(\"validation\")\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e75e161",
   "metadata": {},
   "source": [
    "Generate custom torch datasets to use dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56265a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cpu\n",
      "CustomTorchImageDataset initialized with 897 samples.\n",
      "CustomTorchImageDataset initialized with 179 samples.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Device: \", device)\n",
    "\n",
    "torch_train_dataset = CustomTorchImageDataset(\n",
    "    fiftyone_dataset=train_dataset,\n",
    "    img_size=IMG_SIZE,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "torch_val_dataset = CustomTorchImageDataset(\n",
    "    fiftyone_dataset=val_dataset,\n",
    "    img_size=IMG_SIZE,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6f878b",
   "metadata": {},
   "source": [
    "Create a DataLoader and use a deterministic setup for training to make the results reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30fed1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = create_deterministic_training_dataloader(\n",
    "    torch_train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    torch_val_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03530a7",
   "metadata": {},
   "source": [
    "Create a concatinated dataset for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88ebf880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples in concat dataset: 1076\n"
     ]
    }
   ],
   "source": [
    "concat_dataset = ConcatDataset([torch_train_dataset, torch_val_dataset])\n",
    "print(f\"Total samples in concat dataset: {len(concat_dataset)}\")\n",
    "\n",
    "concat_dataloader = DataLoader(\n",
    "    concat_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105fb6ab",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12e658f",
   "metadata": {},
   "source": [
    "For the loss function, we use the same one as in the assessment: **BCEWithLogitsLoss**. This loss works well with a single output neuron for binary classification. In later tasks, we set *num_classes=1* to ensure the model has only one output neuron, which aligns with this loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47632dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e424abd",
   "metadata": {},
   "source": [
    "We initialize our table for the comparison of the different architectures at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c6685f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = [\n",
    "    [\"Metric\", \"Validation Loss\", \"Parameters (M)\", \"Training Time\", \"Final Accuracy\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaee71a",
   "metadata": {},
   "source": [
    "We define hyperparameters that are shared between both architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bc067ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "rgb_ch = 4\n",
    "xyz_ch = 4\n",
    "lr = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b51ff8f",
   "metadata": {},
   "source": [
    "# MaxPool2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b18cfd0",
   "metadata": {},
   "source": [
    "First, we start with the **MaxPool2d** version of the fusion model. This was already trained in the last notebook. To make them more independent, we train it here again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ce966a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/matti/Master/3. Semester/Hands-on Computer Vision/lab2/CILP-Assessment-Multimodal-Learning/notebooks/wandb/run-20251226_134637-0qlbk429</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment/runs/0qlbk429' target=\"_blank\">ConcatIntermediateNet</a></strong> to <a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment' target=\"_blank\">https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment/runs/0qlbk429' target=\"_blank\">https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment/runs/0qlbk429</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mm_max_pool_net\n",
      "All random seeds set to 51 for reproducibility\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁█</td></tr><tr><td>learning_rate</td><td>▁▁</td></tr><tr><td>train_loss</td><td>█▁</td></tr><tr><td>valid_loss</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>2</td></tr><tr><td>learning_rate</td><td>0.0001</td></tr><tr><td>train_loss</td><td>0.23266</td></tr><tr><td>valid_loss</td><td>0.21223</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ConcatIntermediateNet</strong> at: <a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment/runs/0qlbk429' target=\"_blank\">https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment/runs/0qlbk429</a><br> View project at: <a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment' target=\"_blank\">https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251226_134637-0qlbk429/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mm_max_pool_net = ConcatIntermediateNet(rgb_ch, xyz_ch).to(device)\n",
    "mm_max_pool_opt = Adam(mm_max_pool_net.parameters(), lr=lr)\n",
    "mm_max_pool_save_path = Path.cwd().parent / \"checkpoints\" / \"03_mm_max_pool_model.pth\"\n",
    "mm_max_pool_run = wandb.init(project=PROJECT_NAME, name=f\"{ConcatIntermediateNet.__name__}\")\n",
    "\n",
    "print(\"Training mm_max_pool_net\")\n",
    "set_seeds(51)\n",
    "mm_max_pool_train_loss, mm_max_pool_valid_loss, mm_max_pool_train_time = train_model(\n",
    "    mm_max_pool_net,\n",
    "    mm_max_pool_opt,\n",
    "    loss_func,\n",
    "    get_mm_intermediate_inputs,\n",
    "    epochs,\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    save_path=mm_max_pool_save_path,\n",
    "    run=mm_max_pool_run,\n",
    ")\n",
    "mm_max_pool_num_params = mm_max_pool_net.get_number_of_parameters() / 1e6  # in millions\n",
    "\n",
    "mm_max_pool_run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218996b9",
   "metadata": {},
   "source": [
    "Load best model and calculate accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c674a9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mm_max_pool_model = ConcatIntermediateNet(rgb_ch, xyz_ch).to(device)\n",
    "best_mm_max_pool_model.load_state_dict(torch.load(mm_max_pool_save_path))\n",
    "\n",
    "mm_max_pool_accuracy, _ = infer_model(\n",
    "    best_mm_max_pool_model,\n",
    "    concat_dataloader,\n",
    "    get_mm_intermediate_inputs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1895a91b",
   "metadata": {},
   "source": [
    "Add metrics to table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d34c7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.append([\n",
    "    \"MaxPool2d\",\n",
    "    np.min(mm_max_pool_valid_loss),\n",
    "    mm_max_pool_num_params,\n",
    "    mm_max_pool_train_time,\n",
    "    mm_max_pool_accuracy,\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee49c81",
   "metadata": {},
   "source": [
    "# Strided Conv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b197141b",
   "metadata": {},
   "source": [
    "Now, we train the model using the **Strided Conv** version. Here, we removed the pooling layers and added stride to the convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc981a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/matti/Master/3. Semester/Hands-on Computer Vision/lab2/CILP-Assessment-Multimodal-Learning/notebooks/wandb/run-20251226_134658-ke8zx9be</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment/runs/ke8zx9be' target=\"_blank\">ConcatIntermediateNetWithStride</a></strong> to <a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment' target=\"_blank\">https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment/runs/ke8zx9be' target=\"_blank\">https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment/runs/ke8zx9be</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mm_stride_net\n",
      "All random seeds set to 51 for reproducibility\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁█</td></tr><tr><td>learning_rate</td><td>▁▁</td></tr><tr><td>train_loss</td><td>█▁</td></tr><tr><td>valid_loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>2</td></tr><tr><td>learning_rate</td><td>0.0001</td></tr><tr><td>train_loss</td><td>0.23844</td></tr><tr><td>valid_loss</td><td>0.20609</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ConcatIntermediateNetWithStride</strong> at: <a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment/runs/ke8zx9be' target=\"_blank\">https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment/runs/ke8zx9be</a><br> View project at: <a href='https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment' target=\"_blank\">https://wandb.ai/karl-schuetz-hasso-plattner-institut/cilp-extended-assessment</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251226_134658-ke8zx9be/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mm_stride_net = ConcatIntermediateNetWithStride(rgb_ch, xyz_ch).to(device)\n",
    "mm_stride_opt = Adam(mm_stride_net.parameters(), lr=lr)\n",
    "mm_stride_save_path = Path.cwd().parent / \"checkpoints\" / \"03_mm_stride_model.pth\"\n",
    "mm_stride_run = wandb.init(project=PROJECT_NAME, name=f\"{ConcatIntermediateNetWithStride.__name__}\")\n",
    "\n",
    "print(\"Training mm_stride_net\")\n",
    "set_seeds(51)\n",
    "mm_stride_train_loss, mm_stride_valid_loss, mm_stride_train_time = train_model(\n",
    "    mm_stride_net,\n",
    "    mm_stride_opt,\n",
    "    loss_func,\n",
    "    get_mm_intermediate_inputs,\n",
    "    epochs,\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    save_path=mm_stride_save_path,\n",
    "    run=mm_stride_run,\n",
    ")\n",
    "mm_stride_num_params = mm_stride_net.get_number_of_parameters() / 1e6  # in millions\n",
    "\n",
    "mm_stride_run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0edf06",
   "metadata": {},
   "source": [
    "Load best model and calculate accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c05444c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mm_stride_model = ConcatIntermediateNetWithStride(rgb_ch, xyz_ch).to(device)\n",
    "best_mm_stride_model.load_state_dict(torch.load(mm_stride_save_path))\n",
    "\n",
    "mm_stride_accuracy, _ = infer_model(\n",
    "    best_mm_stride_model,\n",
    "    concat_dataloader,\n",
    "    get_mm_intermediate_inputs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734bf97f",
   "metadata": {},
   "source": [
    "Add metrics to table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c0d01f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.append([\n",
    "    \"Strid-2 Conv2d\",\n",
    "    np.min(mm_stride_valid_loss),\n",
    "    mm_stride_num_params,\n",
    "    mm_stride_train_time,\n",
    "    mm_stride_accuracy,\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde6499e",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fea94b7",
   "metadata": {},
   "source": [
    "We calculate the differences for all our metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5309d753",
   "metadata": {},
   "outputs": [],
   "source": [
    "differences = [\"Difference\"]\n",
    "for i in range(1, len(table[0])):\n",
    "    differences.append(table[2][i] - table[1][i])\n",
    "table.append(differences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a8dbe7",
   "metadata": {},
   "source": [
    "Print the comparision table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b12ed8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------+------------------+--------------+\n",
      "| Metric          |   MaxPool2d |   Strid-2 Conv2d |   Difference |\n",
      "+=================+=============+==================+==============+\n",
      "| Validation Loss |   0.207008  |       0.20609    | -0.000918161 |\n",
      "+-----------------+-------------+------------------+--------------+\n",
      "| Parameters (M)  |  13.0159    |      13.0159     |  0           |\n",
      "+-----------------+-------------+------------------+--------------+\n",
      "| Training Time   |   7.09494   |       4.75805    | -2.33689     |\n",
      "+-----------------+-------------+------------------+--------------+\n",
      "| Final Accuracy  |   0.0288104 |       0.00743494 | -0.0213755   |\n",
      "+-----------------+-------------+------------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "rows = list(zip(*table)) # transpose for tabulate\n",
    "print(tabulate(rows[1:], headers=rows[0], tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b99363",
   "metadata": {},
   "source": [
    "## Theoretical Differences\n",
    "Both approaches reduce the spatial size of an activation map, but they do so in different ways.\n",
    "\n",
    "MaxPool2D selects the maximum value within each 2×2 window (with kernel size of 2). This halves the height and width of the activation map without learning any new parameters. Pooling is therefore parameter-free and purely statistical.\n",
    "\n",
    "Strided Convolution reduces spatial resolution by moving the convolution filter. The stride defines how many pixels the filter shifts after each convolution step. A stride of 2 skips every second position in both spatial dimensions. Unlike pooling, this operation is learnable because the convolution weights are trained. The downsampling is therefore coupled with feature extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028d8c89",
   "metadata": {},
   "source": [
    "## Impact on Gradient Flow and learned Features\n",
    "Because MaxPool2D is not learnable, gradients do not pass through pooling weights (there are none). Gradients only flow back to the max-selected elements, meaning some activations receive no gradient signal. This can make the model slightly more selective and introduce sparsity.\n",
    "\n",
    "In contrast, Strided Convolution learns both feature extraction and downsampling jointly. This means, that gradients propagate through the convolution weights and more elements contribute to the backward pass."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be149f1",
   "metadata": {},
   "source": [
    "## Recommendation with Justification\n",
    "Use Strided Convolution when you want:\n",
    "\n",
    "the model to learn how to downsample\n",
    "\n",
    "richer, more flexible feature learning\n",
    "\n",
    "tighter control over how spatial information is preserved\n",
    "\n",
    "Use MaxPool2D when you want:\n",
    "\n",
    "a simpler, parameter-free downsampling method\n",
    "\n",
    "stronger spatial invariance and feature sparsity\n",
    "\n",
    "a slight regularization effect"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
